# ğŸŸ£ Repo Scan Template

Use this template for **one file per scanned repo** under `Findings/Repo/`.

## File Template
```md
# ğŸŸ£ Repo <repo-name>

## ğŸ—ºï¸ Architecture Diagram
```mermaid
flowchart TB
  Dev[<repo-name> repo] --> CI[<CI/CD system>]
  CI --> Build[Build/Test]

  Build --> IaC[IaC / App]
  IaC --> Cloud[Cloud Resources]
  Cloud --> Deps[Service Dependencies]

  CI -. secrets scanning .-> Secrets[Secret scanning]
```

- **Overall Score:** <severity emoji + label> <score>/10

## ğŸ§­ Overview
<short overview of the repository purpose and key findings>

## ğŸ›¡ï¸ Security Review
### Languages & Frameworks (extracted)
- <language/framework> â€” evidence: `<path>`

### ğŸ§¾ Summary
<short summary of material risks>

### âœ… Applicability
- **Status:** Yes / No / Donâ€™t know
- **Evidence:** <what was observed>

### âš ï¸ Assumptions
- <assumption that could change score/applicability> (mark as Confirmed/Unconfirmed)

### ğŸ¯ Exploitability
<how an attacker would realistically leverage issues>

### ğŸš© Risks
- <bullet list of notable risks/issues; link to related cloud/code findings if they exist>

### ğŸ” Key Evidence (deep dive)
Mark each deep-dive evidence item:
- ğŸ’¡ = notable signal / observed component / in-use indicator (neutral)
- âœ… = observed guardrail / good practice / risk reducer (positive)
- âŒ = observed weakness / insecure default / risk increaser (negative)

For secret-like signals (password, token, etc):
- If used inside a module: check module code before flagging as âŒ (may be securely handled)
- If output is consumed by secure storage (e.g., Key Vault): flag as ğŸ’¡ or âœ… depending on context
- Only flag as âŒ if cleartext exposure or insecure handling is confirmed

Examples:
- ğŸ’¡ Terraform module in use â€” evidence: `modules/azure/resource.tf:42:module "firewall_rules" {`
- âœ… Secret stored via Key Vault module â€” evidence: `main.tf:15:module.key_vault.store_secret`
- âŒ Cleartext secret in pipeline variable â€” evidence: `pipeline.yml:20:ARM_CLIENT_SECRET=$plaintext`

### Follow-up tasks for repo owners (optional)
- [ ] <what to verify> â€” evidence/source to check: `<path>`

### Cloud Environment Implications
Capture any **reusable** cloud context inferred from the repo (IaC + app config).
Promote reusable facts into `Knowledge/` as **Confirmed**/**Assumptions**.

- **Provider(s) referenced:** <Azure/AWS/GCP>
- **Cloud resources/services deployed or referenced:** <Key Vault, Storage, AKS, ACR, SQL, ...>
- **Network posture patterns:** <public endpoints, private endpoints, etc>
- **Identity patterns:** <managed identity/workload identity/roles>
- **Guardrails:** <policy-as-code, module standards, CI checks>

### Service Dependencies (from config / connection strings)
Extract downstream dependencies indicated by configuration, e.g.:
- DBs: Postgres/MySQL/MSSQL/Cosmos
- Queues/streams: Service Bus/Event Hub/Kafka
- Logs/telemetry: App Insights/Log Analytics/Datadog/Splunk
- APIs: internal/external base URLs

- **Datastores:** <...>
- **Messaging:** <...>
- **Logging/Monitoring:** <...>
- **External APIs:** <...>

### Containers / Kubernetes (inferred)
- If `skaffold.yaml`, Helm charts, or Kubernetes manifests are present: assume **Kubernetes** deploy.
- If `Dockerfile`(s) are present: assume a **container registry** is in use.
- If multiple Dockerfiles/Helm charts exist: identify base images (`FROM ...`) and note supply-chain risks.

- **Kubernetes tooling found:** <skaffold/helm/kustomize/manifests>
- **Container build artifacts:** <Dockerfile paths>
- **Base images:** <list of FROM images>

### âœ… Recommendations
- [ ] <recommendation> â€” â¬‡ï¸ <score>â¡ï¸<reduced-score> (est.)

### ğŸ“ Rationale
<why the score is what it is>

## ğŸ¤” Skeptic
> Purpose: review the **Security Review** above, then add what a security engineer would miss on a first pass.

### ğŸ› ï¸ Dev
- **Whatâ€™s missing/wrong vs Security Review:** <call out gaps, incorrect assumptions, or missing context>
- **Score recommendation:** â¡ï¸ Keep/â¬†ï¸ Up/â¬‡ï¸ Down â€” *explicitly state why vs the Security Review score*.
- **How it could be worse:** <realistic attacker path leveraging repo/app/IaC>
- **Countermeasure effectiveness:** <which recommendations measurably reduce risk; which are hygiene>
- **Assumptions to validate:** <which assumptions would change applicability/score>

### ğŸ—ï¸ Platform
- **Whatâ€™s missing/wrong vs Security Review:** <call out gaps, incorrect assumptions, or missing context>
- **Score recommendation:** â¡ï¸ Keep/â¬†ï¸ Up/â¬‡ï¸ Down â€” *explicitly state why vs the Security Review score*.
- **Operational constraints:** <pipelines, auth to cloud, network reachability, rollout sequencing>
- **Countermeasure effectiveness:** <guardrail coverage, drift prevention, enforceability>
- **Assumptions to validate:** <which assumptions would change applicability/score>

## ğŸ¤ Collaboration
- **Outcome:** <outcome>
- **Next step:** <next step>

## Compounding Findings
- **Compounds with:** <finding list or None identified>
  (use Markdown backlinks, e.g., `Findings/Cloud/Foo.md`)

## Meta Data
<!-- Meta Data must remain the final section in the file. -->
- **Repo Name:** <repo-name>
- **Repo Path:** <absolute local path>
- **Repo URL:** <url or N/A>
- **Repo Type:** <Terraform/Go/Node.js/etc + purpose>
- **Languages/Frameworks:** <comma-separated list>
- **CI/CD:** <Azure Pipelines/GitHub Actions/etc or N/A>
- **Scan Scope:** <SAST / dependency (SCA) / secrets / IaC / All>
- **Scanner:** <tool name>
- ğŸ—“ï¸ **Last updated:** DD/MM/YYYY HH:MM
```
